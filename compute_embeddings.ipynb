{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import walk, rename\n",
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Along this notebook we generate the embeddings of the answers predicted and the ground truth topic labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Generate the embedding model to generate the embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the model to compute the embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answers embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. For the answers saved in path *dir_path*, generate the embedding with the *model* of each answer and store the embedding in a *.pt* file in the folder defined in *emb_path*.\n",
    "There might be more than one answer file in *dir_path*, it browses all the files and generates all the embeddings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['topics_results_4_bart-tl-ng.json', 'topics_results_10_bart-tl-ng.json', 'topics_results_4_bart-tl-all.json', 'topics_results_10_bart-tl-all.json']\n"
     ]
    }
   ],
   "source": [
    "# Define the path where the predicted answers are stored\n",
    "dir_path = \"Bart-TL/\"\n",
    "# Define the path where the QA embeddings are to be stored\n",
    "emb_path = \"Bart-TL/BartEmbeddings/all-MiniLM-L6-v2/\"\n",
    "\n",
    "# List the names of the files that store the QA answers\n",
    "files = []\n",
    "for (_, _, file_names) in walk(dir_path):\n",
    "    files.extend(file_names)\n",
    "print(files)\n",
    "\n",
    "# For each file listed\n",
    "for f in files:\n",
    "    # Read the json file (answers)\n",
    "    data = pd.read_json(dir_path+f)\n",
    "    # Extract the asnwers as sentences\n",
    "    sentences = data['Answer']\n",
    "\n",
    "    # Encode list of sentences to get their embeddings\n",
    "    embedding = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Define the embedding id\n",
    "    i = 0\n",
    "    # Extract the name of the file read\n",
    "    f_n = f.replace(\".json\",\"\")\n",
    "    # For each computed embedding (each answer embedding)\n",
    "    for e in embedding:\n",
    "        # Save the embedding as a torch tensor with id i\n",
    "        torch.save(e, emb_path+'tensor_'+f_n+'_'+str(i)+'.pt')\n",
    "        i+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topics embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Read the ground truth labels from the topic JSON file, generate the embedding with the *model* of each label and store the embedding in a *.pt* file in the folder defined in *emb_path*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                   name  \\\n",
      "0    0           sport hockey   \n",
      "1    1       religion atheism   \n",
      "2    2          science space   \n",
      "3    3       science medicine   \n",
      "4    4          politics_misc   \n",
      "5    5  computer mac hardware   \n",
      "6    6       politics mideast   \n",
      "7    7  computer ibm hardware   \n",
      "8    8               for sale   \n",
      "9    9    science electronics   \n",
      "10  10  computer windows misc   \n",
      "11  11       motor motorcycle   \n",
      "12  12         sport baseball   \n",
      "13  13     religion christian   \n",
      "14  14          politics guns   \n",
      "15  15      computer graphics   \n",
      "16  16            motor autos   \n",
      "17  17          religion misc   \n",
      "18  18     computer windows x   \n",
      "19  19          science crypt   \n",
      "\n",
      "                                          description  \n",
      "0   game,team,play,hockey,player,win,goal,season,f...  \n",
      "1   god,religion,atheist,moral,claim,point,objecti...  \n",
      "2   space,nasa,launch,system,orbit,earth,mission,s...  \n",
      "3   patient,disease,medical,doctor,study,food,heal...  \n",
      "4   government,president,state,law,work,give,man,a...  \n",
      "5   mac,apple,problem,drive,system,work,monitor,co...  \n",
      "6   armenian,israel,turkish,jew,arab,israeli,musli...  \n",
      "7   drive,card,system,problem,work,controller,disk...  \n",
      "8   offer,sale,sell,include,drive,price,shipping,c...  \n",
      "9   work,circuit,ground,power,wire,good,line,find,...  \n",
      "10  window,file,run,driver,problem,program,work,ca...  \n",
      "11  bike,ride,dod,motorcycle,dog,good,bmw,work,rid...  \n",
      "12  game,team,win,hit,player,run,baseball,good,pla...  \n",
      "13  god,christian,church,jesus,christ,sin,bible,gi...  \n",
      "14  gun,government,weapon,state,fire,law,firearm,f...  \n",
      "15  image,file,graphic,jpeg,program,format,system,...  \n",
      "16  car,engine,drive,good,buy,problem,dealer,price...  \n",
      "17  god,jesus,christian,fact,good,objective,theory...  \n",
      "18  window,file,program,run,server,application,wid...  \n",
      "19  key,chip,encryption,government,system,clipper,...  \n"
     ]
    }
   ],
   "source": [
    "# Define the path where the topics' GT embeddings are to be stored\n",
    "emb_path = \"Eval/QAEmbeddings/all-MiniLM-L6-v2/topics/\"\n",
    "\n",
    "# Read the topics\n",
    "topics = pd.read_json(\"topics_20news.json\")\n",
    "# Extract the topics' names as sentences\n",
    "sentences = topics['name']\n",
    "\n",
    "# Encode list of sentences to get their embeddings\n",
    "embedding = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# Define the embedding id\n",
    "i = 0\n",
    "# For each computed embedding (each answer embedding)\n",
    "for e in embedding:\n",
    "    # Save the embedding as a torch tensor with id i\n",
    "    torch.save(e, emb_path+'tensor_topic_'+str(i)+'.pt')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
