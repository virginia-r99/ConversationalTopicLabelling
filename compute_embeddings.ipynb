{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import walk, rename\n",
    "import torch"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answers embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['topics_results_4_bart-tl-ng.json', 'topics_results_10_bart-tl-ng.json', 'topics_results_4_bart-tl-all.json', 'topics_results_10_bart-tl-all.json']\n"
     ]
    }
   ],
   "source": [
    "# Define the model to compute the embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define the path where the Bert answers are stored\n",
    "dir_path = \"Bart-TL/\"\n",
    "# Define the path where the QA embeddings are to be stored\n",
    "emb_path = \"Bart-TL/BartEmbeddings/all-MiniLM-L6-v2/\"\n",
    "\n",
    "# List the names of the files that store the QA answers\n",
    "files = []\n",
    "for (_, _, file_names) in walk(dir_path):\n",
    "    files.extend(file_names)\n",
    "print(files)\n",
    "\n",
    "# For each file listed\n",
    "for f in files:\n",
    "    # Read the json file (answers)\n",
    "    data = pd.read_json(dir_path+f)\n",
    "    # Extract the asnwers as sentences\n",
    "    sentences = data['Answer']\n",
    "\n",
    "    # Encode list of sentences to get their embeddings\n",
    "    embedding = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "    # Define the embedding id\n",
    "    i = 0\n",
    "    # Extract the name of the file read\n",
    "    f_n = f.replace(\".json\",\"\")\n",
    "    # For each computed embedding (each answer embedding)\n",
    "    for e in embedding:\n",
    "        # Save the embedding as a torch tensor with id i\n",
    "        torch.save(e, emb_path+'tensor_'+f_n+'_'+str(i)+'.pt')\n",
    "        i+=1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topics embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    id                   name  \\\n",
      "0    0           sport hockey   \n",
      "1    1       religion atheism   \n",
      "2    2          science space   \n",
      "3    3       science medicine   \n",
      "4    4          politics_misc   \n",
      "5    5  computer mac hardware   \n",
      "6    6       politics mideast   \n",
      "7    7  computer ibm hardware   \n",
      "8    8               for sale   \n",
      "9    9    science electronics   \n",
      "10  10  computer windows misc   \n",
      "11  11       motor motorcycle   \n",
      "12  12         sport baseball   \n",
      "13  13     religion christian   \n",
      "14  14          politics guns   \n",
      "15  15      computer graphics   \n",
      "16  16            motor autos   \n",
      "17  17          religion misc   \n",
      "18  18     computer windows x   \n",
      "19  19          science crypt   \n",
      "\n",
      "                                          description  \n",
      "0   game,team,play,hockey,player,win,goal,season,f...  \n",
      "1   god,religion,atheist,moral,claim,point,objecti...  \n",
      "2   space,nasa,launch,system,orbit,earth,mission,s...  \n",
      "3   patient,disease,medical,doctor,study,food,heal...  \n",
      "4   government,president,state,law,work,give,man,a...  \n",
      "5   mac,apple,problem,drive,system,work,monitor,co...  \n",
      "6   armenian,israel,turkish,jew,arab,israeli,musli...  \n",
      "7   drive,card,system,problem,work,controller,disk...  \n",
      "8   offer,sale,sell,include,drive,price,shipping,c...  \n",
      "9   work,circuit,ground,power,wire,good,line,find,...  \n",
      "10  window,file,run,driver,problem,program,work,ca...  \n",
      "11  bike,ride,dod,motorcycle,dog,good,bmw,work,rid...  \n",
      "12  game,team,win,hit,player,run,baseball,good,pla...  \n",
      "13  god,christian,church,jesus,christ,sin,bible,gi...  \n",
      "14  gun,government,weapon,state,fire,law,firearm,f...  \n",
      "15  image,file,graphic,jpeg,program,format,system,...  \n",
      "16  car,engine,drive,good,buy,problem,dealer,price...  \n",
      "17  god,jesus,christian,fact,good,objective,theory...  \n",
      "18  window,file,program,run,server,application,wid...  \n",
      "19  key,chip,encryption,government,system,clipper,...  \n"
     ]
    }
   ],
   "source": [
    "# Define the model to compute the embeddings\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "# Define the path where the topics' GT embeddings are to be stored\n",
    "emb_path = \"Eval/QAEmbeddings/all-MiniLM-L6-v2/topics/\"\n",
    "\n",
    "# Read the topics\n",
    "topics = pd.read_json(\"topics_20news.json\")\n",
    "# Extract the topics' names as sentences\n",
    "sentences = topics['name']\n",
    "\n",
    "# Encode list of sentences to get their embeddings\n",
    "embedding = model.encode(sentences, convert_to_tensor=True)\n",
    "\n",
    "# Define the embedding id\n",
    "i = 0\n",
    "# For each computed embedding (each answer embedding)\n",
    "for e in embedding:\n",
    "    # Save the embedding as a torch tensor with id i\n",
    "    torch.save(e, emb_path+'tensor_topic_'+str(i)+'.pt')\n",
    "    i+=1"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
