{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from os import walk,rename\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the topics (names and descriptions)\n",
    "topics = pd.read_json(\"topics_20news.json\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONV. SIMILARITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   topics\n",
      "0            sport hockey\n",
      "1        religion atheism\n",
      "2           science space\n",
      "3        science medicine\n",
      "4           politics_misc\n",
      "5   computer mac hardware\n",
      "6        politics mideast\n",
      "7   computer ibm hardware\n",
      "8                for sale\n",
      "9     science electronics\n",
      "10  computer windows misc\n",
      "11       motor motorcycle\n",
      "12         sport baseball\n",
      "13     religion christian\n",
      "14          politics guns\n",
      "15      computer graphics\n",
      "16            motor autos\n",
      "17          religion misc\n",
      "18     computer windows x\n",
      "19          science crypt\n"
     ]
    }
   ],
   "source": [
    "# Extract the topics' names and define a results dataframe to save similarities\n",
    "results = pd.DataFrame({'topics':topics['name']})\n",
    "# Show topics' names\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of conversational models\n",
    "#conv_models = [\"blenderbot-400M-distill\",\"DialoGPT-medium\",\"ChatGPT\"]\n",
    "conv_models = [\"bart-tl-all\",\"bart-tl-ng\"]\n",
    "\n",
    "# Define the embedding model name\n",
    "#emb_model = \"all-mpnet-base-v2\"\n",
    "emb_model = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Define the path where the embeddings of the topics are stored\n",
    "emb_topic_path = \"Bart-TL/BartEmbeddings/\"+emb_model+\"/topics/\"\n",
    "\n",
    "# Define the name of the question structure used\n",
    "q = \"q3\"\n",
    "\n",
    "# Define the number of words to be used\n",
    "num = [4,10]\n",
    "# For each number of words\n",
    "for i in num:\n",
    "    # Define the path where the embeddings of the answers are stored\n",
    "    emb_path = \"Bart-TL/BartEmbeddings/\"+emb_model+\"/\"\n",
    "    # Define the path where the similarities are to be stored\n",
    "    sim_path = \"Bart-TL/Similarities/\"\n",
    "    \n",
    "    # For each conversational model\n",
    "    for c in conv_models:\n",
    "        # Array to save the similarities\n",
    "        sims = []\n",
    "        # Define the prefix name of the similarities' files of the conversational model c with i words\n",
    "        #prefix = \"tensor_\"+q+\"_topics_results_\"+str(i)+\"_\"+c+\"_\"\n",
    "        prefix = \"tensor_topics_results_\"+str(i)+\"_\"+c+\"_\"\n",
    "        # For each topic (we have 20 topics)\n",
    "        for j in range(0,20):\n",
    "            # Define the path of the file where the conversational answer tensor for topic j is\n",
    "            t_answ_name = emb_path+prefix+str(j)+\".pt\"\n",
    "            # Define the path of the file where the groud truth tensor for topic j is\n",
    "            t_topic_name = emb_topic_path+\"tensor_topic_\"+str(j)+\".pt\"\n",
    "            # Load the conv. answer and GT tensors\n",
    "            emb_answ = torch.load(t_answ_name)\n",
    "            emb_topic = torch.load(t_topic_name)\n",
    "\n",
    "            # Compute similarity scores of the two embeddings/tensors\n",
    "            cosine_scores = util.pytorch_cos_sim(emb_topic, emb_answ)\n",
    "            # Save the similarity value\n",
    "            sims.append(cosine_scores[0][0].item())\n",
    "        # Store the similarities by id topic\n",
    "        d = {\"id\":range(0,20),\"cosine_sim\":sims}\n",
    "        df = pd.DataFrame(data=d)\n",
    "        # Save the results in a json file\n",
    "        df.to_json(sim_path+q+\"_topics_results_\"+str(i)+\"_\"+emb_model+\"_\"+c+\".json\")\n",
    "        # Save the results for each combination of conv. model and num. of words in a 'results' dataframe\n",
    "        results[str(i)+\"_\"+c] = sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "      <th>4_bart-tl-all</th>\n",
       "      <th>4_bart-tl-ng</th>\n",
       "      <th>10_bart-tl-all</th>\n",
       "      <th>10_bart-tl-ng</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport hockey</td>\n",
       "      <td>0.455012</td>\n",
       "      <td>0.455012</td>\n",
       "      <td>0.053746</td>\n",
       "      <td>0.210210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>religion atheism</td>\n",
       "      <td>0.586220</td>\n",
       "      <td>0.191222</td>\n",
       "      <td>0.536015</td>\n",
       "      <td>0.136997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science space</td>\n",
       "      <td>0.350002</td>\n",
       "      <td>0.350003</td>\n",
       "      <td>0.350003</td>\n",
       "      <td>0.350003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science medicine</td>\n",
       "      <td>0.252070</td>\n",
       "      <td>0.190956</td>\n",
       "      <td>0.168083</td>\n",
       "      <td>0.279395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics_misc</td>\n",
       "      <td>0.226567</td>\n",
       "      <td>0.226567</td>\n",
       "      <td>0.331462</td>\n",
       "      <td>0.185002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>computer mac hardware</td>\n",
       "      <td>0.433676</td>\n",
       "      <td>0.387201</td>\n",
       "      <td>0.387201</td>\n",
       "      <td>0.387201</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics mideast</td>\n",
       "      <td>0.261565</td>\n",
       "      <td>0.113921</td>\n",
       "      <td>0.362944</td>\n",
       "      <td>0.113921</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>computer ibm hardware</td>\n",
       "      <td>0.436425</td>\n",
       "      <td>0.423988</td>\n",
       "      <td>0.329375</td>\n",
       "      <td>0.423988</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for sale</td>\n",
       "      <td>0.162414</td>\n",
       "      <td>0.404935</td>\n",
       "      <td>0.404935</td>\n",
       "      <td>0.404935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>science electronics</td>\n",
       "      <td>0.055412</td>\n",
       "      <td>0.312479</td>\n",
       "      <td>0.162447</td>\n",
       "      <td>0.323538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>computer windows misc</td>\n",
       "      <td>0.342185</td>\n",
       "      <td>0.485278</td>\n",
       "      <td>0.214941</td>\n",
       "      <td>0.214941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>motor motorcycle</td>\n",
       "      <td>0.904174</td>\n",
       "      <td>0.904174</td>\n",
       "      <td>0.076015</td>\n",
       "      <td>0.076015</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sport baseball</td>\n",
       "      <td>0.459002</td>\n",
       "      <td>0.459002</td>\n",
       "      <td>0.459002</td>\n",
       "      <td>0.187961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>religion christian</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.829337</td>\n",
       "      <td>0.474334</td>\n",
       "      <td>0.829337</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>politics guns</td>\n",
       "      <td>0.186532</td>\n",
       "      <td>0.186532</td>\n",
       "      <td>0.186532</td>\n",
       "      <td>0.333961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>computer graphics</td>\n",
       "      <td>0.227405</td>\n",
       "      <td>0.227405</td>\n",
       "      <td>0.579564</td>\n",
       "      <td>0.236793</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>motor autos</td>\n",
       "      <td>0.088624</td>\n",
       "      <td>0.579330</td>\n",
       "      <td>0.195199</td>\n",
       "      <td>0.195199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>religion misc</td>\n",
       "      <td>0.639544</td>\n",
       "      <td>0.639544</td>\n",
       "      <td>0.639544</td>\n",
       "      <td>0.639544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>computer windows x</td>\n",
       "      <td>0.383527</td>\n",
       "      <td>0.383527</td>\n",
       "      <td>0.286654</td>\n",
       "      <td>0.181907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>science crypt</td>\n",
       "      <td>0.361185</td>\n",
       "      <td>0.145967</td>\n",
       "      <td>0.021636</td>\n",
       "      <td>0.192911</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   topics  4_bart-tl-all  4_bart-tl-ng  10_bart-tl-all  \\\n",
       "0            sport hockey       0.455012      0.455012        0.053746   \n",
       "1        religion atheism       0.586220      0.191222        0.536015   \n",
       "2           science space       0.350002      0.350003        0.350003   \n",
       "3        science medicine       0.252070      0.190956        0.168083   \n",
       "4           politics_misc       0.226567      0.226567        0.331462   \n",
       "5   computer mac hardware       0.433676      0.387201        0.387201   \n",
       "6        politics mideast       0.261565      0.113921        0.362944   \n",
       "7   computer ibm hardware       0.436425      0.423988        0.329375   \n",
       "8                for sale       0.162414      0.404935        0.404935   \n",
       "9     science electronics       0.055412      0.312479        0.162447   \n",
       "10  computer windows misc       0.342185      0.485278        0.214941   \n",
       "11       motor motorcycle       0.904174      0.904174        0.076015   \n",
       "12         sport baseball       0.459002      0.459002        0.459002   \n",
       "13     religion christian       0.829337      0.829337        0.474334   \n",
       "14          politics guns       0.186532      0.186532        0.186532   \n",
       "15      computer graphics       0.227405      0.227405        0.579564   \n",
       "16            motor autos       0.088624      0.579330        0.195199   \n",
       "17          religion misc       0.639544      0.639544        0.639544   \n",
       "18     computer windows x       0.383527      0.383527        0.286654   \n",
       "19          science crypt       0.361185      0.145967        0.021636   \n",
       "\n",
       "    10_bart-tl-ng  \n",
       "0        0.210210  \n",
       "1        0.136997  \n",
       "2        0.350003  \n",
       "3        0.279395  \n",
       "4        0.185002  \n",
       "5        0.387201  \n",
       "6        0.113921  \n",
       "7        0.423988  \n",
       "8        0.404935  \n",
       "9        0.323538  \n",
       "10       0.214941  \n",
       "11       0.076015  \n",
       "12       0.187961  \n",
       "13       0.829337  \n",
       "14       0.333961  \n",
       "15       0.236793  \n",
       "16       0.195199  \n",
       "17       0.639544  \n",
       "18       0.181907  \n",
       "19       0.192911  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the results as an xlsx file\n",
    "results.to_excel(\"Bart-TL/Bart_Evaluation_\"+emb_model+\".xlsx\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# QA SIMILARITIES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>topics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sport hockey</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>religion atheism</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>science space</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>science medicine</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>politics_misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>computer mac hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>politics mideast</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>computer ibm hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>for sale</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>science electronics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>computer windows misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>motor motorcycle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>sport baseball</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>religion christian</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>politics guns</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>computer graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>motor autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>religion misc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>computer windows x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>science crypt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                   topics\n",
       "0            sport hockey\n",
       "1        religion atheism\n",
       "2           science space\n",
       "3        science medicine\n",
       "4           politics_misc\n",
       "5   computer mac hardware\n",
       "6        politics mideast\n",
       "7   computer ibm hardware\n",
       "8                for sale\n",
       "9     science electronics\n",
       "10  computer windows misc\n",
       "11       motor motorcycle\n",
       "12         sport baseball\n",
       "13     religion christian\n",
       "14          politics guns\n",
       "15      computer graphics\n",
       "16            motor autos\n",
       "17          religion misc\n",
       "18     computer windows x\n",
       "19          science crypt"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Extract the topics' names and define a results dataframe to save similarities\n",
    "results = pd.DataFrame({'topics':topics['name']})\n",
    "# Show topics' names\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the name of conversational models\n",
    "conv_models = [\"blenderbot-400M-distill\",\"DialoGPT-medium\",\"ChatGPT\"]\n",
    "\n",
    "# Define the name of QA models\n",
    "#qa_models = [\"deberta-v3-large-squad2\",\"deberta-v3-base-squad2\", \"xlm-roberta-large-squad2\",\\\n",
    "#              \"bert-large-uncased-whole-word-masking-squad2\", \"roberta-base-squad2-distilled\"]\n",
    "qa_models = [\"deberta-v3-base-squad2\", \"bert-large-uncased-whole-word-masking-squad2\", \"roberta-base-squad2-distilled\"]\n",
    "\n",
    "# Define the embedding model name\n",
    "#emb_model = \"all-mpnet-base-v2\"\n",
    "emb_model = \"all-MiniLM-L6-v2\"\n",
    "\n",
    "# Define the path where the embeddings of the topics are stored\n",
    "emb_topic_path = \"Eval/QAEmbeddings/\"+emb_model+\"/topics/\"\n",
    "\n",
    "# Define the name of the question structure used\n",
    "q = \"q3\"\n",
    "\n",
    "# Define the number of words to be used\n",
    "num = [4,9,10]\n",
    "# For each QA model\n",
    "for qa in qa_models:\n",
    "    # For each number of words\n",
    "    for i in num:\n",
    "        # Define the path where the embeddings of the answers are stored\n",
    "        emb_path = \"Eval/QAEmbeddings/\"+emb_model+\"/\"\n",
    "        # Define the path where the similarities are to be stored\n",
    "        sim_path = \"Eval/QASimilarities/\"\n",
    "        \n",
    "        # For each conversational model\n",
    "        for c in conv_models:\n",
    "             # Array to save the similarities\n",
    "            sims = []\n",
    "            # Define the prefix name of the similarities' files of the conversational model c, QA model qa with i words\n",
    "            prefix = \"tensor_\"+q+\"_topics_results_\"+str(i)+\"_\"+c+\"_\"+qa+\"_\"\n",
    "            # For each topic (we have 20 topics)\n",
    "            for j in range(0,20):\n",
    "                # Define the path of the file where the QA answer tensor for topic j is\n",
    "                t_answ_name = emb_path+prefix+str(j)+\".pt\"\n",
    "                 # Define the path of the file where the groud truth tensor for topic j is\n",
    "                t_topic_name = emb_topic_path+\"tensor_topic_\"+str(j)+\".pt\"\n",
    "                # Load the conv. answer and GT tensors\n",
    "                emb_answ = torch.load(t_answ_name)\n",
    "                emb_topic = torch.load(t_topic_name)\n",
    "\n",
    "                # Compute similarity scores of the two embeddings/tensors\n",
    "                cosine_scores = util.pytorch_cos_sim(emb_topic, emb_answ)\n",
    "                # Save the similarity value\n",
    "                sims.append(cosine_scores[0][0].item())\n",
    "\n",
    "            # Store the similarities by id topic\n",
    "            d = {\"id\":range(0,20),\"cosine_sim\":sims}\n",
    "            df = pd.DataFrame(data=d)\n",
    "             # Save the results in a json file\n",
    "            df.to_json(sim_path+q+\"_topics_results_\"+str(i)+\"_\"+emb_model+\"_\"+c+\"_\"+qa+\".json\")\n",
    "             # Save the results for each combination of conv. model, QA model and num. of words in a 'results' dataframe\n",
    "            results[str(i)+\"_\"+c+\"_\"+qa] = sims\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all the results as an xlsx file\n",
    "results.to_excel(\"Eval/QA_Evaluation_\"+emb_model+\".xlsx\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
